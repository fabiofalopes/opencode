# üîç RELAT√ìRIO: An√°lise Cr√≠tica do Problema do Agente Conductor

**Data:** 2026-01-06
**Sess√£o:** An√°lise profunda de configura√ß√£o
**Status:** üî¥ CR√çTICO - Problema Identificado

---

## üìã Resumo Executivo

O agente **Conductor** est√° a falhar na sua fun√ß√£o de orquestrador por um **problema fundamental de design**: quando configurado para delegar tarefas, se o modelo n√£o conseguir reconhecer ou implementar o protocolo de delega√ß√£o via ferramenta `task`, ele recai para comportamentos de fallback que o tornam in√∫til (output de texto gen√©rico sem a√ß√µes concretas).

**Sintoma Principal:** O Conductor diz ao utilizador o que fazer, em vez de delegar para subagentes que o fazem por si.

---

## üèóÔ∏è Arquitetura Atual

### Configura√ß√£o do Conductor

**Ficheiro:** `.opencode/agent/conductor.md`

```yaml
tools:
  write: false
  edit: false
  bash: false
  read: true
  grep: true
  glob: true
  list: true
  patch: false
  todowrite: true
  todoread: true
  task: true            # ‚Üê FERRAMENTA CR√çTICA PARA DELEGA√á√ÉO
  sequential_thinking: true

permission:
  edit: deny
  bash: deny
  webfetch: deny
```

**Modelo Atual (do perfil `copilot`):**
- `github-copilot/claude-sonnet-4.5`

**Ferramentas Dispon√≠veis:**
1. ‚úÖ `task` - Delegar para subagentes
2. ‚úÖ `todowrite`/`todoread` - Gerir estado
3. ‚úÖ `sequential_thinking` - Pensamento estruturado
4. ‚úÖ `read`/`grep`/`glob`/`list` - Leitura apenas
5. ‚ùå `write`/`edit`/`bash` - DESATIVADOS (por design)

---

## ‚ö†Ô∏è O Problema: Gap de Implementa√ß√£o

### O que DEVE acontecer (Design):

```
1. Receber pedido do utilizador
2. Usar sequential_thinking para decompor em passos
3. Iniciar todowrite com os passos
4. Para cada passo:
   a. Determinar qual subagente √© apropriado
   b. Usar ferramenta task() com instru√ß√µes claras
   c. AGUARDAR resultado do subagente
   d. Validar output e atualizar todowrite
5. Finalizar
```

### O que EST√Å a acontecer (Realidade):

```
1. Receber pedido do utilizador
2. Usar sequential_thinking (‚úÖ works)
3. Iniciar todowrite (‚úÖ works)
4. Para cada passo:
   a. Determinar subagente (‚úÖ works)
   b. [GAP] N√£o invoca task() - em vez disso:
      - Gera texto: "Delegaria para @code para fazer X"
      - OU: "O agente @code faria: passos 1, 2, 3..."
      - OU: "Recomendo que executes estes comandos..."
   c. ‚úó NADA √© executado
   d. ‚úó todowrite fica inalterado
5. ‚úó Usu√°rio frustrado
```

---

## üî¨ An√°lise das Causas Raiz

### 1. **Ambiguidade na Prompt do Conductor**

**Problema:** O prompt diz "delegar", mas n√£o diz **COMO** delegar programaticamente.

**Excerto do prompt atual (linha 38-47):**
```markdown
## 2. Delegation Protocol (The Handoff)
- Use the `task` tool to call sub-agents.
- **CRITICAL**: Execute ONE task at a time. Wait for the result.
- **Handoff Template**:
  Target: @[agent]
  Input: [Specific context/files/goal]
  Constraints: [What NOT to do]
  Expected Output: [Format/Result]
```

**Avalia√ß√£o:** ‚ùå AMBIGUO
- Explica O QU√ä, mas n√£o o COMO t√©cnico
- N√£o mostra exemplos de chamada real da ferramenta `task`
- N√£o enfatiza que **S√ì** funciona via invoca√ß√£o da ferramenta
- Modelo pode interpretar como "explicar a delega√ß√£o" em vez de "executar delega√ß√£o"

### 2. **Comportamento de Fallback do Modelo**

Quando o modelo √© treinado para ser √∫til mas tem ferramentas restritas:

| Op√ß√£o | Comportamento | Resultado |
|--------|---------------|-----------|
| Op√ß√£o A | Tentar usar write/edit/bash | üî¥ BLOCKED (permission deny) |
| Op√ß√£o B | Usar task() | üü¢ VALID, mas **n√£o treinado** |
| Op√ß√£o C | Explicar em texto | üü° Fallback - **n√£o executa** |

**Modelo escolhe Op√ß√£o C** porque:
- √â o path de menor resist√™ncia
- "Explicar" parece √∫til para o utilizador
- N√£o h√° refor√ßo expl√≠cito para invocar task()
- O padr√£o de conversa√ß√£o natural √© dizer, n√£o executar

### 3. **Falta de Exemplos Concretos**

O prompt do Conductor **N√ÉO tem exemplos de uso da ferramenta `task`**:

```markdown
# ‚ùå O que existe agora:
Target: @[agent]
Input: [Specific context/files/goal]
Constraints: [What NOT to do]
Expected Output: [Format/Result]

# ‚ùå O que falta:
# Exemplo de uso real:
task(
  subagent_type="code",
  prompt="Create a REST API endpoint at /api/users with CRUD operations",
  description="Implement users API endpoint"
)

# Output esperado:
# @code: [Executes and returns result]
```

---

## üß™ Contexto da M√°quina Atual

**M√°quina:** `linux-vm` (zabbix)
**Plataforma:** Linux
**Utilizador:** dsi
**Working Directory:** `/home/dsi/.config/opencode`

**Perfis Dispon√≠veis:**
1. ‚úÖ `zens` - OpenCode Zens (Minimax & GLM) - **FREE, Unlimited**
2. ‚úÖ `gemini` - Google Gemini 3 - **FREE**
3. ‚úÖ `copilot` - GitHub Copilot - **PAID** (Atual)
4. ‚úÖ `grok` - OpenCode Grok - **FREE, Single model**

**Modelo Atual:** `github-copilot/claude-sonnet-4.5`

---

## üéØ An√°lise Comportamental: Por que funciona "√†s vezes"?

O utilizador reportou: *"parece que vai de funcionar incrivelmente bem... para faz o m√≠nimo poss√≠vel"*

### An√°lise do Comportamento Inconsistente

**Cen√°rio A: Funciona bem**
- Prompt: "Configure o OpenCode para usar Gemini"
- Conductor reconhece que √© uma **tarefa de configura√ß√£o**
- Tem instru√ß√µes expl√≠citas na prompt (opencode-config-manager)
- **Invoca task() com @opencode-config-manager**
- Resultado: ‚úÖ Tarefa completada

**Cen√°rio B: Fails**
- Prompt: "Implemente uma API REST com FastAPI"
- Conductor precisa decompor em m√∫ltiplas tarefas:
  1. @know para pesquisar FastAPI
  2. @plan para arquitetura
  3. @code para implementa√ß√£o
  4. @scribe para documenta√ß√£o
- **Gap:** Modelo n√£o "internaliza" que PRECISA invocar task() para cada passo
- Em vez disso, gera: "Delegaria para @know para pesquisar..."
- Resultado: ‚ùå Nada acontece

**Hip√≥tese:** O modelo pode estar a falhar porque:
- A prompt n√£o usa `Few-Shot Prompting` (exemplos m√∫ltiplos)
- N√£o h√° exemplos negativos ("N√ÉO fa√ßa isto:")
- A ordem de preced√™ncia de ferramentas n√£o est√° clara
- O modelo n√£o sabe que `task()` √© a √öNICA forma de progresso

---

## üîç Investiga√ß√£o T√©cnica

### Ferramenta `task()` - Como funciona

**Defini√ß√£o na interface:**
```typescript
task(
  subagent_type: "general" | "explore" | "code" | "research" | "thinking" | "scribe" | "policy",
  prompt: string,
  description?: string
)
```

**Fluxo de execu√ß√£o:**
1. Conductor invoca `task()` com par√¢metros
2. OpenCode inicializa o subagente especificado
3. Subagente executa com suas pr√≥prias ferramentas
4. Resultado √© retornado ao Conductor
5. Conductor processa resultado e atualiza estado

**Pontos Cr√≠ticos:**
- ‚úÖ Conductor N√ÉO executa c√≥digo direto
- ‚úÖ Subagentes t√™m permiss√µes diferenciadas
- ‚úÖ Cada subagente usa modelo espec√≠fico
- ‚ùå **N√£o h√° valida√ß√£o que task() foi invocado**

---

## üìä Estado da Configura√ß√£o

### MCP Servers Ativos

**Funcionando (11):**
- ‚úÖ code_interpreter
- ‚úÖ context7
- ‚úÖ gh_grep
- ‚úÖ duckduckgo
- ‚úÖ fetch
- ‚úÖ sequential_thinking
- ‚úÖ memory
- ‚úÖ wikipedia
- ‚úÖ arxiv
- ‚úÖ paper_search
- ‚úÖ hackernews

**Com Problemas (6):**
- ‚ùå content_pdf_marker (timeout)
- ‚ùå content_pdf_reader (connection closed)
- ‚ùå perplexity (connection closed)
- ‚ùå memory_vector_qdrant (connection closed)
- ‚ùå research_scraper_firecrawl (connection closed)
- ‚ùå research_search_searxng (connection closed)

**Desativados (6):**
- ‚ö™ ollama_bridge
- ‚ö™ qdrant_mcp
- ‚ö™ neo4j_mcp
- ‚ö™ brave
- ‚ö™ github
- ‚ö™ integration_suite_aio

**Nota:** O estado dos MCPs **N√ÉO afeta** o problema do Conductor, pois ele n√£o usa MCPs diretamente para delega√ß√£o.

---

## üêõ Diagn√≥stico Espec√≠fico

### Problema Identificado: **"Orchestration Gap"**

**Componente Causador:** Prompt insuficiente do Conductor

**Sintomas:**
1. Modelo n√£o invoca `task()` consistentemente
2. Recai para output de texto descritivo
3. Usu√°rio fica com instru√ß√µes manuais sem execu√ß√£o
4. Sess√£o estagna com "roadblocks fict√≠cios"

**Impacto:**
- üî¥ Alto - Torna o Conductor in√∫til em tarefas complexas
- üî¥ M√©dio - Reduz confian√ßa do utilizador no sistema
- üî¥ Baixo - Nenhum impacto em agentes individuais (funcionam bem)

---

## üí° Solu√ß√µes Propostas (Priorit√°rias)

### üî• Solu√ß√£o 1: Reescrever a Prompt do Conductor com Few-Shot Examples

**Objetivo:** Fornecer exemplos concretos de uso da ferramenta `task()`

**Abordagem:**
```markdown
## 3. Delegation Protocol (COM INVOCAR)

### INCORRETO ‚ùå
"Delegaria para @code para criar o ficheiro main.py"
Resultado: Nada acontece. O utilizador recebe apenas texto.

### CORRETO ‚úÖ
```python
task(
  subagent_type="code",
  prompt="Create main.py with a FastAPI application",
  description="Implement FastAPI main file"
)
```
Resultado: @code √© invocado, executa a tarefa, retorna resultado.

### Exemplos Completos

**Exemplo 1: Tarefa Simples**
Input: "Create a Python script to parse JSON files"

Sua a√ß√£o:
1. todowrite: [{"id": "1", "content": "Create JSON parser script", "status": "in_progress"}]
2. task(
     subagent_type="code",
     prompt="Create a Python script that parses JSON files from a directory and outputs summary statistics",
     description="Implement JSON parser script"
   )
3. [Wait for result]
4. todowrite: [{"id": "1", "content": "Create JSON parser script", "status": "completed"}]
```

**Vantagem:** Treina o modelo com exemplos positivos e negativos.

### üî• Solu√ß√£o 2: Adicionar Valida√ß√£o de Ferramenta

**Objetivo:** Garantir que `task()` seja invocado quando apropriado

**Implementa√ß√£o (no prompt):**
```markdown
## CRITICAL RULE: Progress via task() Only

Before any output, ask yourself:
- "Did I invoke task() to execute this work?"
- If NO: You MUST invoke task() before responding.
- If YES: You can report the result.

You cannot complete work without invoking task().
Writing explanations is NOT completing work.
```

**Vantagem:** Refor√ßa que progresso s√≥ via `task()`.

### üü° Solu√ß√£o 3: Reduzir Ambiguidade com Ferramentas Restritas

**Objetivo:** Tornar imposs√≠vel o fallback para texto

**Implementa√ß√£o (no prompt):**
```markdown
## RESTRI√á√ïES DE OUTPUT

Voc√™ TEM permiss√£o para:
- ‚úÖ Invocar task()
- ‚úÖ Usar todowrite()
- ‚úÖ Ler ficheiros (read/grep/glob/list)
- ‚úÖ Usar sequential_thinking()

Voc√™ N√ÉO TEM permiss√£o para:
- ‚ùå Descrever o que faria (delegue via task())
- ‚ùå Dar instru√ß√µes ao utilizador (delegue via task())
- ‚ùå Explicar processos sem executar (delegue via task())

Pergunta antes de output: "Esta a√ß√£o executa trabalho real?"
- Se N√ÉO: Use task()
- Se SIM: Pode responder
```

**Vantagem:** Elimina o path de fallback para texto.

---

## üß™ Teste de Hip√≥teses

### Hip√≥tese A: O modelo n√£o entende a sintaxe de task()

**Teste:**
1. Adicionar exemplos de chamada com sintaxe real
2. Executar sess√£o de teste
3. Verificar se invoca task()

**Expectativa:** Se funcionar ‚Üí Solu√ß√£o 1 √© suficiente

### Hip√≥tese B: O modelo prefere explicar em vez de executar

**Teste:**
1. Adicionar regra expl√≠cita de "n√£o explicar sem executar"
2. Executar sess√£o de teste
3. Verificar comportamento

**Expectativa:** Se funcionar ‚Üí Solu√ß√£o 3 √© suficiente

### Hip√≥tese C: O modelo n√£o reconhece prioridade de ferramentas

**Teste:**
1. Reordenar ferramentas no YAML (task primeiro)
2. Executar sess√£o de teste
3. Verificar se prioriza task()

**Expectativa:** Baixa probabilidade de sucesso

---

## üìù Recomenda√ß√µes Imediatas

### 1. TESTAR COM OUTROS MODELOS
- Switchar para perfil `gemini` (google/gemini-3-pro)
- Verificar se modelo do Google responde melhor
- Comparar comportamento entre Claude e Gemini

**Comando:**
```bash
npm run switch:gemini
```

### 2. APLICAR CORRE√á√ïES NA PROMPT
- Reescrever `conductor.md` com Few-Shot Examples
- Adicionar regras de output restritivo
- Enfatizar que `task()` √© a √∫nica forma de progresso

### 3. CRIAR SUITE DE TESTES
- Testar delega√ß√£o com prompts padr√£o
- Verificar se task() √© invocado
- Documentar comportamento por modelo

### 4. CONSIDERAR ARQUITETURA ALTERNATIVA
- Implementar valida√ß√£o externa que force uso de task()
- Criar wrapper que detecta quando Conductor n√£o delega
- Adicionar mensagens de erro expl√≠citas quando task() n√£o √© usado

---

## üéØ Pr√≥ximos Passos Sugeridos

1. **AGORA:** Analisar com o utilizador se quer testar com modelo diferente
2. **HOJE:** Aplicar corre√ß√µes na prompt do Conductor (Solu√ß√µes 1, 2, 3)
3. **AMANH√É:** Criar testes de valida√ß√£o
4. **ESTA SEMANA:** Documentar melhorias e replicar para outros agentes

---

## üîó Refer√™ncias

**Ficheiros Relevantes:**
- `.opencode/agent/conductor.md` - Prompt do Conductor
- `opencode.base.json` - Configura√ß√£o base de agentes
- `profiles.json` - Perfis de modelos
- `AGENTS.md` - Regras gerais de agentes

**Documenta√ß√£o:**
- `docs/AGENT_MD_SCHEMA.md` - Schema de agentes
- `docs/AGENT_SPEC_CONFIG.md` - Especifica√ß√µes de configura√ß√£o
- `docs/SYSTEM_CONTEXT.md` - Contexto do sistema

**Hist√≥rico Recente:**
- Git commit: `1141713` (Merge de branch origin/main)
- Altera√ß√£o em: `opencode.json` (paths atualizados para linux-vm)

---

## üìå Notas para o Utilizador

**O que est√°s a experimentar √© um problema conhecido de agentic AI:**

Quando o modelo n√£o est√° treinado ou explicitamente instru√≠do a usar uma ferramenta espec√≠fica para um prop√≥sito cr√≠tico, ele recorre ao comportamento padr√£o de "ajudar" - que √© explicar, n√£o executar.

**N√£o √© um bug da OpenCode**, mas sim um **gap de prompt engineering** que precisa de ser preenchido com:
- Exemplos claros (Few-Shot)
- Regras restritivas de output
- Valida√ß√£o expl√≠cita de ferramentas

**Boas not√≠cias:** √â fix√°vel com melhorias na prompt, sem necessidade de altera√ß√µes ao core do sistema.

---

**Fim do Relat√≥rio**
**Status:** üî¥ AGUARDANDO DECIS√ÉO DO UTILIZADOR
